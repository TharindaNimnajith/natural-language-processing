{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'nltk' from 'd:\\\\self\\\\natural-language-processing\\\\venv\\\\lib\\\\site-packages\\\\nltk\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "print(nltk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['AbstractLazySequence',\n 'AffixTagger',\n 'AlignedSent',\n 'Alignment',\n 'AnnotationTask',\n 'ApplicationExpression',\n 'Assignment',\n 'BigramAssocMeasures',\n 'BigramCollocationFinder',\n 'BigramTagger',\n 'BinaryMaxentFeatureEncoding',\n 'BlanklineTokenizer',\n 'BllipParser',\n 'BottomUpChartParser',\n 'BottomUpLeftCornerChartParser',\n 'BottomUpProbabilisticChartParser',\n 'Boxer',\n 'BrillTagger',\n 'BrillTaggerTrainer',\n 'CFG',\n 'CRFTagger',\n 'CfgReadingCommand',\n 'ChartParser',\n 'ChunkParserI',\n 'ChunkScore',\n 'Cistem',\n 'ClassifierBasedPOSTagger',\n 'ClassifierBasedTagger',\n 'ClassifierI',\n 'ConcordanceIndex',\n 'ConditionalExponentialClassifier',\n 'ConditionalFreqDist',\n 'ConditionalProbDist',\n 'ConditionalProbDistI',\n 'ConfusionMatrix',\n 'ContextIndex',\n 'ContextTagger',\n 'ContingencyMeasures',\n 'CoreNLPDependencyParser',\n 'CoreNLPParser',\n 'Counter',\n 'CrossValidationProbDist',\n 'DRS',\n 'DecisionTreeClassifier',\n 'DefaultTagger',\n 'DependencyEvaluator',\n 'DependencyGrammar',\n 'DependencyGraph',\n 'DependencyProduction',\n 'DictionaryConditionalProbDist',\n 'DictionaryProbDist',\n 'DiscourseTester',\n 'DrtExpression',\n 'DrtGlueReadingCommand',\n 'ELEProbDist',\n 'EarleyChartParser',\n 'Expression',\n 'FStructure',\n 'FeatDict',\n 'FeatList',\n 'FeatStruct',\n 'FeatStructReader',\n 'Feature',\n 'FeatureBottomUpChartParser',\n 'FeatureBottomUpLeftCornerChartParser',\n 'FeatureChartParser',\n 'FeatureEarleyChartParser',\n 'FeatureIncrementalBottomUpChartParser',\n 'FeatureIncrementalBottomUpLeftCornerChartParser',\n 'FeatureIncrementalChartParser',\n 'FeatureIncrementalTopDownChartParser',\n 'FeatureTopDownChartParser',\n 'FreqDist',\n 'HTTPPasswordMgrWithDefaultRealm',\n 'HeldoutProbDist',\n 'HiddenMarkovModelTagger',\n 'HiddenMarkovModelTrainer',\n 'HunposTagger',\n 'IBMModel',\n 'IBMModel1',\n 'IBMModel2',\n 'IBMModel3',\n 'IBMModel4',\n 'IBMModel5',\n 'ISRIStemmer',\n 'ImmutableMultiParentedTree',\n 'ImmutableParentedTree',\n 'ImmutableProbabilisticMixIn',\n 'ImmutableProbabilisticTree',\n 'ImmutableTree',\n 'IncrementalBottomUpChartParser',\n 'IncrementalBottomUpLeftCornerChartParser',\n 'IncrementalChartParser',\n 'IncrementalLeftCornerChartParser',\n 'IncrementalTopDownChartParser',\n 'Index',\n 'InsideChartParser',\n 'JSONTaggedDecoder',\n 'JSONTaggedEncoder',\n 'KneserNeyProbDist',\n 'LancasterStemmer',\n 'LaplaceProbDist',\n 'LazyConcatenation',\n 'LazyEnumerate',\n 'LazyIteratorList',\n 'LazyMap',\n 'LazySubsequence',\n 'LazyZip',\n 'LeftCornerChartParser',\n 'LidstoneProbDist',\n 'LineTokenizer',\n 'LogicalExpressionException',\n 'LongestChartParser',\n 'MLEProbDist',\n 'MWETokenizer',\n 'Mace',\n 'MaceCommand',\n 'MaltParser',\n 'MaxentClassifier',\n 'Model',\n 'MultiClassifierI',\n 'MultiParentedTree',\n 'MutableProbDist',\n 'NLTKWordTokenizer',\n 'NaiveBayesClassifier',\n 'NaiveBayesDependencyScorer',\n 'NgramAssocMeasures',\n 'NgramTagger',\n 'NonprojectiveDependencyParser',\n 'Nonterminal',\n 'OrderedDict',\n 'PCFG',\n 'Paice',\n 'ParallelProverBuilder',\n 'ParallelProverBuilderCommand',\n 'ParentedTree',\n 'ParserI',\n 'PerceptronTagger',\n 'PhraseTable',\n 'PorterStemmer',\n 'PositiveNaiveBayesClassifier',\n 'ProbDistI',\n 'ProbabilisticDependencyGrammar',\n 'ProbabilisticMixIn',\n 'ProbabilisticNonprojectiveParser',\n 'ProbabilisticProduction',\n 'ProbabilisticProjectiveDependencyParser',\n 'ProbabilisticTree',\n 'Production',\n 'ProjectiveDependencyParser',\n 'Prover9',\n 'Prover9Command',\n 'ProxyBasicAuthHandler',\n 'ProxyDigestAuthHandler',\n 'ProxyHandler',\n 'PunktSentenceTokenizer',\n 'QuadgramAssocMeasures',\n 'QuadgramCollocationFinder',\n 'RSLPStemmer',\n 'RTEFeatureExtractor',\n 'RUS_PICKLE',\n 'RandomChartParser',\n 'RangeFeature',\n 'ReadingCommand',\n 'RecursiveDescentParser',\n 'RegexpChunkParser',\n 'RegexpParser',\n 'RegexpStemmer',\n 'RegexpTagger',\n 'RegexpTokenizer',\n 'ReppTokenizer',\n 'ResolutionProver',\n 'ResolutionProverCommand',\n 'SExprTokenizer',\n 'SLASH',\n 'Senna',\n 'SennaChunkTagger',\n 'SennaNERTagger',\n 'SennaTagger',\n 'SequentialBackoffTagger',\n 'ShiftReduceParser',\n 'SimpleGoodTuringProbDist',\n 'SklearnClassifier',\n 'SlashFeature',\n 'SnowballStemmer',\n 'SpaceTokenizer',\n 'StackDecoder',\n 'StanfordNERTagger',\n 'StanfordPOSTagger',\n 'StanfordSegmenter',\n 'StanfordTagger',\n 'StemmerI',\n 'SteppingChartParser',\n 'SteppingRecursiveDescentParser',\n 'SteppingShiftReduceParser',\n 'SyllableTokenizer',\n 'TYPE',\n 'TabTokenizer',\n 'TableauProver',\n 'TableauProverCommand',\n 'TaggerI',\n 'TestGrammar',\n 'Text',\n 'TextCat',\n 'TextCollection',\n 'TextTilingTokenizer',\n 'TnT',\n 'TokenSearcher',\n 'ToktokTokenizer',\n 'TopDownChartParser',\n 'TransitionParser',\n 'Tree',\n 'TreebankWordTokenizer',\n 'Trie',\n 'TrigramAssocMeasures',\n 'TrigramCollocationFinder',\n 'TrigramTagger',\n 'TweetTokenizer',\n 'TypedMaxentFeatureEncoding',\n 'Undefined',\n 'UniformProbDist',\n 'UnigramTagger',\n 'UnsortedChartParser',\n 'Valuation',\n 'Variable',\n 'ViterbiParser',\n 'WekaClassifier',\n 'WhitespaceTokenizer',\n 'WittenBellProbDist',\n 'WordNetLemmatizer',\n 'WordPunctTokenizer',\n '__author__',\n '__author_email__',\n '__builtins__',\n '__cached__',\n '__classifiers__',\n '__copyright__',\n '__doc__',\n '__file__',\n '__keywords__',\n '__license__',\n '__loader__',\n '__longdescr__',\n '__maintainer__',\n '__maintainer_email__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '__url__',\n '__version__',\n 'accuracy',\n 'add_logs',\n 'agreement',\n 'align',\n 'alignment_error_rate',\n 'aline',\n 'api',\n 'app',\n 'apply_features',\n 'approxrand',\n 'arity',\n 'association',\n 'bigrams',\n 'binary_distance',\n 'binary_search_file',\n 'binding_ops',\n 'bisect',\n 'blankline_tokenize',\n 'bleu',\n 'bleu_score',\n 'bllip',\n 'boolean_ops',\n 'boxer',\n 'bracket_parse',\n 'breadth_first',\n 'brill',\n 'brill_trainer',\n 'build_opener',\n 'call_megam',\n 'casual',\n 'casual_tokenize',\n 'ccg',\n 'chain',\n 'chart',\n 'chat',\n 'choose',\n 'chunk',\n 'cistem',\n 'classify',\n 'clause',\n 'clean_html',\n 'clean_url',\n 'collections',\n 'collocations',\n 'combinations',\n 'compat',\n 'config_java',\n 'config_megam',\n 'config_weka',\n 'conflicts',\n 'confusionmatrix',\n 'conllstr2tree',\n 'conlltags2tree',\n 'corenlp',\n 'corpus',\n 'crf',\n 'custom_distance',\n 'data',\n 'decisiontree',\n 'decorator',\n 'decorators',\n 'defaultdict',\n 'demo',\n 'dependencygraph',\n 'deque',\n 'destructive',\n 'discourse',\n 'distance',\n 'download',\n 'download_gui',\n 'download_shell',\n 'downloader',\n 'draw',\n 'drt',\n 'earleychart',\n 'edit_distance',\n 'edit_distance_align',\n 'elementtree_indent',\n 'entropy',\n 'equality_preds',\n 'evaluate',\n 'evaluate_sents',\n 'everygrams',\n 'extract_rels',\n 'extract_test_sentences',\n 'f_measure',\n 'featstruct',\n 'featurechart',\n 'filestring',\n 'find',\n 'flatten',\n 'fractional_presence',\n 'getproxies',\n 'ghd',\n 'glue',\n 'grammar',\n 'guess_encoding',\n 'help',\n 'hmm',\n 'hunpos',\n 'ibm1',\n 'ibm2',\n 'ibm3',\n 'ibm4',\n 'ibm5',\n 'ibm_model',\n 'ieerstr2tree',\n 'in_idle',\n 'induce_pcfg',\n 'inference',\n 'infile',\n 'inspect',\n 'install_opener',\n 'internals',\n 'interpret_sents',\n 'interval_distance',\n 'invert_dict',\n 'invert_graph',\n 'is_rel',\n 'islice',\n 'isri',\n 'jaccard_distance',\n 'json_tags',\n 'jsontags',\n 'lancaster',\n 'lazyimport',\n 'lfg',\n 'line_tokenize',\n 'linearlogic',\n 'lm',\n 'load',\n 'load_parser',\n 'locale',\n 'log_likelihood',\n 'logic',\n 'mace',\n 'malt',\n 'map_tag',\n 'mapping',\n 'masi_distance',\n 'maxent',\n 'megam',\n 'memoize',\n 'meteor',\n 'meteor_score',\n 'metrics',\n 'misc',\n 'mwe',\n 'naivebayes',\n 'ne_chunk',\n 'ne_chunk_sents',\n 'ngrams',\n 'nonprojectivedependencyparser',\n 'nonterminals',\n 'os',\n 'pad_sequence',\n 'paice',\n 'pairwise',\n 'parallelize_preprocess',\n 'parse',\n 'parse_sents',\n 'pchart',\n 'perceptron',\n 'pk',\n 'porter',\n 'pos_tag',\n 'pos_tag_sents',\n 'positivenaivebayes',\n 'pprint',\n 'pr',\n 'precision',\n 'presence',\n 'print_string',\n 'probability',\n 'projectivedependencyparser',\n 'prover9',\n 'punkt',\n 'py25',\n 'py26',\n 'py27',\n 'pydoc',\n 'raise_unorderable_types',\n 'ranks_from_scores',\n 'ranks_from_sequence',\n 're',\n 're_show',\n 'read_grammar',\n 'read_logic',\n 'read_valuation',\n 'recall',\n 'recursivedescent',\n 'regexp',\n 'regexp_span_tokenize',\n 'regexp_tokenize',\n 'register_tag',\n 'relextract',\n 'repp',\n 'resolution',\n 'ribes',\n 'ribes_score',\n 'root_semrep',\n 'rslp',\n 'rte_classifier',\n 'rte_classify',\n 'rte_features',\n 'rtuple',\n 'scikitlearn',\n 'scores',\n 'segmentation',\n 'sem',\n 'senna',\n 'sent_tokenize',\n 'sequential',\n 'set2rel',\n 'set_proxy',\n 'sexpr',\n 'sexpr_tokenize',\n 'shiftreduce',\n 'simple',\n 'sinica_parse',\n 'skipgrams',\n 'skolemize',\n 'slice_bounds',\n 'snowball',\n 'sonority_sequencing',\n 'spearman',\n 'spearman_correlation',\n 'stack_decoder',\n 'stanford',\n 'stanford_segmenter',\n 'stem',\n 'str2tuple',\n 'string_span_tokenize',\n 'subprocess',\n 'subsumes',\n 'sum_logs',\n 'sys',\n 'tableau',\n 'tadm',\n 'tag',\n 'tagset_mapping',\n 'tagstr2tree',\n 'tbl',\n 'tee',\n 'text',\n 'textcat',\n 'texttiling',\n 'textwrap',\n 'tkinter',\n 'tnt',\n 'tokenize',\n 'tokenwrap',\n 'toktok',\n 'toolbox',\n 'total_ordering',\n 'transitionparser',\n 'transitive_closure',\n 'translate',\n 'tree',\n 'tree2conllstr',\n 'tree2conlltags',\n 'treebank',\n 'treetransforms',\n 'trigrams',\n 'tuple2str',\n 'types',\n 'unify',\n 'unique_list',\n 'untag',\n 'usage',\n 'util',\n 'version_file',\n 'version_info',\n 'viterbi',\n 'weka',\n 'windowdiff',\n 'word_tokenize',\n 'wordnet',\n 'wordpunct_tokenize',\n 'wsd']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk:\n",
      "\n",
      "NAME\n",
      "    nltk\n",
      "\n",
      "DESCRIPTION\n",
      "    The Natural Language Toolkit (NLTK) is an open source Python library\n",
      "    for Natural Language Processing.  A free online book is available.\n",
      "    (If you use the library for academic research, please cite the book.)\n",
      "    \n",
      "    Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
      "    Natural Language Processing with Python.  O'Reilly Media Inc.\n",
      "    http://nltk.org/book\n",
      "    \n",
      "    @version: 3.5\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    app (package)\n",
      "    book\n",
      "    ccg (package)\n",
      "    chat (package)\n",
      "    chunk (package)\n",
      "    classify (package)\n",
      "    cli\n",
      "    cluster (package)\n",
      "    collections\n",
      "    collocations\n",
      "    compat\n",
      "    corpus (package)\n",
      "    data\n",
      "    decorators\n",
      "    downloader\n",
      "    draw (package)\n",
      "    featstruct\n",
      "    grammar\n",
      "    help\n",
      "    inference (package)\n",
      "    internals\n",
      "    jsontags\n",
      "    lazyimport\n",
      "    lm (package)\n",
      "    metrics (package)\n",
      "    misc (package)\n",
      "    parse (package)\n",
      "    probability\n",
      "    sem (package)\n",
      "    sentiment (package)\n",
      "    stem (package)\n",
      "    tag (package)\n",
      "    tbl (package)\n",
      "    test (package)\n",
      "    text\n",
      "    tgrep\n",
      "    tokenize (package)\n",
      "    toolbox\n",
      "    translate (package)\n",
      "    tree\n",
      "    treeprettyprinter\n",
      "    treetransforms\n",
      "    twitter (package)\n",
      "    util\n",
      "    wsd\n",
      "\n",
      "SUBMODULES\n",
      "    agreement\n",
      "    aline\n",
      "    api\n",
      "    association\n",
      "    bleu_score\n",
      "    bllip\n",
      "    boxer\n",
      "    brill\n",
      "    brill_trainer\n",
      "    casual\n",
      "    chart\n",
      "    cistem\n",
      "    confusionmatrix\n",
      "    corenlp\n",
      "    crf\n",
      "    decisiontree\n",
      "    dependencygraph\n",
      "    destructive\n",
      "    discourse\n",
      "    distance\n",
      "    drt\n",
      "    earleychart\n",
      "    evaluate\n",
      "    featurechart\n",
      "    glue\n",
      "    hmm\n",
      "    hunpos\n",
      "    ibm1\n",
      "    ibm2\n",
      "    ibm3\n",
      "    ibm4\n",
      "    ibm5\n",
      "    ibm_model\n",
      "    isri\n",
      "    lancaster\n",
      "    lfg\n",
      "    linearlogic\n",
      "    logic\n",
      "    mace\n",
      "    malt\n",
      "    mapping\n",
      "    maxent\n",
      "    megam\n",
      "    meteor_score\n",
      "    mwe\n",
      "    naivebayes\n",
      "    nonprojectivedependencyparser\n",
      "    paice\n",
      "    pchart\n",
      "    perceptron\n",
      "    porter\n",
      "    positivenaivebayes\n",
      "    projectivedependencyparser\n",
      "    prover9\n",
      "    punkt\n",
      "    recursivedescent\n",
      "    regexp\n",
      "    relextract\n",
      "    repp\n",
      "    resolution\n",
      "    ribes_score\n",
      "    rslp\n",
      "    rte_classify\n",
      "    scikitlearn\n",
      "    scores\n",
      "    segmentation\n",
      "    senna\n",
      "    sequential\n",
      "    sexpr\n",
      "    shiftreduce\n",
      "    simple\n",
      "    snowball\n",
      "    sonority_sequencing\n",
      "    spearman\n",
      "    stack_decoder\n",
      "    stanford\n",
      "    stanford_segmenter\n",
      "    tableau\n",
      "    tadm\n",
      "    textcat\n",
      "    texttiling\n",
      "    tnt\n",
      "    toktok\n",
      "    transitionparser\n",
      "    treebank\n",
      "    viterbi\n",
      "    weka\n",
      "    wordnet\n",
      "\n",
      "FUNCTIONS\n",
      "    demo()\n",
      "        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n",
      "    \n",
      "    tee(iterable, n=2, /)\n",
      "        Returns a tuple of n independent iterators.\n",
      "\n",
      "DATA\n",
      "    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n",
      "    SLASH = *slash*\n",
      "    TYPE = *type*\n",
      "    __author_email__ = 'stevenbird1@gmail.com'\n",
      "    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n",
      "    __copyright__ = 'Copyright (C) 2001-2020 NLTK Project.\\n\\nDistribut......\n",
      "    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n",
      "    __license__ = 'Apache License, Version 2.0'\n",
      "    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ... p...\n",
      "    __maintainer__ = 'Steven Bird, Edward Loper, Ewan Klein'\n",
      "    __maintainer_email__ = 'stevenbird1@gmail.com'\n",
      "    __url__ = 'http://nltk.org/'\n",
      "    app = <LazyModule 'nltk.nltk.app'>\n",
      "    chat = <LazyModule 'nltk.nltk.chat'>\n",
      "    corpus = <LazyModule 'nltk.nltk.corpus'>\n",
      "    infile = <_io.TextIOWrapper name='d:\\\\self\\\\natural-langu...kages\\\\nlt...\n",
      "    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n",
      "    toolbox = <LazyModule 'nltk.nltk.toolbox'>\n",
      "    version_file = r'd:\\self\\natural-language-processing\\venv\\lib\\site-pac...\n",
      "    version_info = sys.version_info(major=3, minor=9, micro=1, releaseleve...\n",
      "\n",
      "VERSION\n",
      "    3.5\n",
      "\n",
      "AUTHOR\n",
      "    Steven Bird, Edward Loper, Ewan Klein\n",
      "\n",
      "FILE\n",
      "    d:\\self\\natural-language-processing\\venv\\lib\\site-packages\\nltk\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}