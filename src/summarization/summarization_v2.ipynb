{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7392 2022 \n",
      "\n",
      "Machine learning and data mining often employ the ame method and overlap ignificantly, but while machine learning focu e on prediction, ba ed on known propertie learned from the training data, data mining focu e on the di covery of (previou ly) unknown propertie in the data (thi i the analy i  tep of knowledge di covery in databa e ).Data mining u e many machine learning method , but with different goal ; on the other hand, machine learning al o employ data mining method a \"un upervi ed learning\" or a a preproce ing tep to improve learner accuracy.Learning cla ifier y tem (LCS) are a family of rule-ba ed machine learning algorithm that combine a di covery component, typically a genetic algorithm, with a learning component, performing either upervi ed learning, reinforcement learning, or un upervi ed learning.Tom M. Mitchell provided a widely quoted, more formal definition of the algorithm  tudied in the machine learning field: \"A computer program i  aid to learn from experience E with re pect to ome cla of ta k T and performance mea ure P if it performance at ta k in T, a mea ured by P, improve with experience E.\" Thi definition of the ta k in which machine learning i concerned offer a fundamentally operational definition rather than defining the field in cognitive term .Semi- upervi ed learning fall between un upervi ed learning (without any labeled training data) and upervi ed learning (with completely labeled training data).Modern day machine learning ha two objective , one i to cla ify data ba ed on model which have been developed, the other purpo e i to make prediction for future outcome ba ed on the e model .It i a powerful tool we are only ju t beginning to under tand, and that i a profound re pon ibility.” \n",
      "Cla ification of machine learning model can be validated by accuracy e timation technique like the holdout method, which plit the data in a training and te t et (conventionally 2/3 training et and 1/3 te t et de ignation) and evaluate the performance of the training model on the te t et.Machine learning approache are traditionally divided into three broad categorie , depending on the nature of the \" ignal\" or \"feedback\" available to the learning y tem:\n",
      "Other approache have been developed which don't fit neatly into thi three-fold categori ation, and ometime more than one i u ed by the ame machine learning y tem.A repre entative book of the machine learning re earch during the 1960 wa the Nil on' book on Learning Machine , dealing mo tly with machine learning for pattern cla ification.A ub et of machine learning i clo ely related to computational tati tic , which focu e on making prediction u ing computer ; but not all machine learning i  tati tical learning.Feature learning algorithm , al o called repre entation learning algorithm , often attempt to pre erve the information in their input but al o tran form it in a way that make it u eful, often a a pre-proce ing tep before performing cla ification or prediction .Similarity learning i an area of upervi ed machine learning clo ely related to regre ion and cla ification, but the goal i to learn from example u ing a imilarity function that mea ure how imilar or related two object are.Federated learning i an adapted form of di tributed artificial intelligence to training machine learning model that decentralize the training proce , allowing for u er ' privacy to be maintained by not needing to end their data to a centralized erver.The difference between optimization and machine learning ari e from the goal of generalization: while optimization algorithm can minimize the lo on a training et, machine learning i concerned with minimizing the lo on un een ample .Spar e dictionary learning i a feature learning method where a training example i repre ented a a linear combination of ba i function , and i a umed to be a par e matrix.A hypothetical algorithm pecific to cla ifying data may u e computer vi ion of mole coupled with upervi ed learning in order to train it to cla ify the cancerou mole .Leo Breiman di tingui hed two tati tical modeling paradigm : data model and algorithmic model, wherein \"algorithmic model\" mean more or le the machine learning algorithm like Random fore t.\n",
      "Some tati tician have adopted method from machine learning, leading to a combined field that they call tati tical learning.Machine learning and tati tic are clo ely related field in term of method , but di tinct in their principal goal: tati tic draw population inference from a ample, while machine learning find generalizable predictive pattern .Support vector machine (SVM ), al o known a  upport vector network , are a et of related upervi ed learning method u ed for cla ification and regre ion.A ociation rule learning i a rule-ba ed machine learning method for di covering relation hip between variable in large databa e .Sy tem which are trained on data et collected with bia e may exhibit the e bia e upon u e (algorithmic bia ), thu digitizing cultural prejudice .Thi replace manual feature engineering, and allow a machine to both learn the feature and u e them to perform a pecific ta k.\n",
      "Feature learning can be either upervi ed or un upervi ed.Concern for fairne in machine learning, that i , reducing bia in machine learning and propelling it u e for human good i increa ingly expre ed by artificial intelligence cienti t , including Fei-Fei Li, who remind engineer that \"There’ nothing artificial about AI...It’ in pired by people, it’ created by people, and—mo t importantly—it impact people.Machine learning algorithm are u ed in a wide variety of application , uch a email filtering and computer vi ion, where it i difficult or unfea ible to develop conventional algorithm to perform the needed ta k .Machine learning y tem u ed for criminal ri k a e ment have been found to be bia ed again t black people.Rule-ba ed machine learning approache include learning cla ifier y tem , a ociation rule learning, and artificial immune y tem .There i huge potential for machine learning in health care to provide profe ional a great tool to diagno e, medicate, and even plan recovery path for patient , but thi will not happen until the per onal bia e mentioned previou ly, and the e \"greed\" bia e are addre ed.Rule-ba ed machine learning i a general term for any machine learning method that identifie , learn , or evolve \"rule \" to tore, manipulate or apply knowledge.Much of the confu ion between the e two re earch communitie (which do often have eparate conference and eparate journal , ECML PKDD being a major exception) come from the ba ic a umption they work with: in machine learning, performance i u ually evaluated with re pect to the ability to reproduce known knowledge, while in knowledge di covery and data mining (KDD) the key ta k i the di covery of previou ly unknown knowledge.Machine learning al o ha intimate tie to optimization: many learning problem are formulated a minimization of ome lo function on a training et of example .Un upervi ed learning algorithm take a et of data that contain only input , and find tructure in the data, like grouping or clu tering of data point .When dealing with non-linear problem , go-to model include polynomial regre ion (for example, u ed for trendline fitting in Micro oft Excel ), logi tic regre ion (often u ed in tati tical cla ification) or even kernel regre ion, which introduce non-linearity by taking advantage of the kernel trick to implicitly map input variable to higher-dimen ional pace.Tree model where the target variable can take a di crete et of value are called cla ification tree ; in the e tree tructure , leave repre ent cla label and branche repre ent conjunction of feature that lead to tho e cla label .Cla ification algorithm are u ed when the output are re tricted to a limited et of value , and regre ion algorithm are u ed when the output may have any numerical value within a range.Feature learning i motivated by the fact that machine learning ta k  uch a cla ification often require input that i mathematically and computationally convenient to proce .Generalization in thi context i the ability of a learning machine to perform accurately on new, un een example /ta k after having experienced a learning data et.In tead of re ponding to feedback, un upervi ed learning algorithm identify commonalitie in the data and react ba ed on the pre ence or ab ence of uch commonalitie in each new piece of data.Deci ion tree learning u e a deci ion tree a a predictive model to go from ob ervation about an item (repre ented in the branche ) to conclu ion about the item' target value (repre ented in the leave ).Characterizing the generalization of variou learning algorithm i an active topic of current re earch, e pecially for deep learning algorithm .Through iterative optimization of an objective function, upervi ed learning algorithm learn a function that can be u ed to predict the output a ociated with new input .Becau e human language contain bia e , machine trained on language corpora will nece arily al o learn the e bia e .For example, Gboard u e federated machine learning to train earch query prediction model on u er ' mobile phone without having to end individual earche back to Google.Machine learning algorithm build a model ba ed on ample data, known a \"training data\", in order to make prediction or deci ion without being explicitly programmed to do o.An algorithm that improve the accuracy of it output or prediction over time i  aid to have learned to perform that ta k. \n",
      "Type of upervi ed learning algorithm include active learning, cla ification and regre ion.Evaluated with re pect to known knowledge, an uninformed (un upervi ed) method will ea ily be outperformed by other upervi ed method , while in a typical KDD ta k, upervi ed method cannot be u ed due to the unavailability of training data.Since the 2010 , advance in both machine learning algorithm and computer hardware have led to more efficient method for training deep neural network (a particular narrow ubdomain of machine learning) that contain many layer of non-linear hidden unit .Reinforcement learning algorithm are u ed in autonomou vehicle or in learning to play a game again t a human opponent.Becau e of uch challenge , the effective u e of machine learning may take longer to be adopted in other domain .Three broad categorie of anomaly detection technique exi t. Un upervi ed anomaly detection technique detect anomalie in an unlabeled te t data et under the a umption that the majority of the in tance in the data et are normal, by looking for in tance that eem to fit lea t to the remainder of the data et.U ually, when training a machine learning model, one need to collect a large, repre entative ample of data from a training et.The computational analy i of machine learning algorithm and their performance i a branch of theoretical computer cience known a computational learning theory.OpenAI e timated the hardware compute u ed in the large t deep learning project from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increa e in the amount of compute required, with a doubling-time trendline of 3.4 month .Supervi ed learning algorithm build a mathematical model of a et of data that contain both the input and the de ired output .The defining characteri tic of a rule-ba ed machine learning algorithm i the identification and utilization of a et of relational rule that collectively repre ent the knowledge captured by the y tem.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import bs4\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from heapq import nlargest\n",
    "\n",
    "text = urllib.request.urlopen('https://en.wikipedia.org/wiki/Machine_learning')\n",
    "article = text.read()\n",
    "\n",
    "# parsing the URL content\n",
    "article_parsed = bs4.BeautifulSoup(article, 'html.parser')\n",
    "\n",
    "# returning <p> tags\n",
    "paragraphs = article_parsed.find_all('p')\n",
    "\n",
    "article_content = ''\n",
    "\n",
    "# getting the content within all paragraphs\n",
    "for p in paragraphs:\n",
    "    article_content += p.text\n",
    "\n",
    "# removing square brackets and extra spaces\n",
    "article_content = re.sub(r'[[0-9]*]', ' ', article_content)\n",
    "article_content = re.sub(r's+', ' ', article_content)\n",
    "\n",
    "# removing special characters and digits\n",
    "formatted_article_content = re.sub('[^a-zA-Z]', ' ', article_content )\n",
    "formatted_article_content = re.sub(r's+', ' ', formatted_article_content)\n",
    "\n",
    "tokens = word_tokenize(formatted_article_content)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punctuation = punctuation + '\\n'\n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in tokens:\n",
    "    if word.lower() not in stop_words:\n",
    "        if word.lower() not in punctuation:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "\n",
    "max_frequency = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word] / max_frequency\n",
    "\n",
    "sent_token = sent_tokenize(article_content)\n",
    "sentence_scores = {}\n",
    "\n",
    "for sent in sent_token:\n",
    "    sentence = sent.split()\n",
    "    for word in sentence:\n",
    "        if word.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.lower()]\n",
    "\n",
    "select_length = int(len(sent_token) * 0.2)\n",
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "final_summary = [word for word in summary]\n",
    "summary = ''.join(final_summary)\n",
    "summary = summary.replace('  ', ' ')\n",
    "\n",
    "print(len(article_content.split()), len(summary.split()), '\\n')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}