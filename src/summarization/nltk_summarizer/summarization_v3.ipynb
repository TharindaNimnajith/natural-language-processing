{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 41 \n",
      "\n",
      "But a Ru ian may need to\n",
      "con ider the gender and a Japane e peaker ha to take into account their hape (long\n",
      "and cylindrical) a well, and u e the number word de ignated for item of that hape.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from heapq import nlargest\n",
    "\n",
    "article_content = '''At first glance the idea seems perfectly plausible. Conveying\n",
    "even simple messages requires that you make completely different observations depending\n",
    "on your language. Imagine being asked to count some pens on a table. As an English\n",
    "speaker, you only have to count them and give the number. But a Russian may need to\n",
    "consider the gender and a Japanese speaker has to take into account their shape (long\n",
    "and cylindrical) as well, and use the number word designated for items of that shape.\n",
    "On the other hand, surely pens are just pens, no matter what your language compels you\n",
    "to specify about them? Little linguistic peculiarities, though amusing, donâ€™t change the\n",
    "objective world we are describing. So how can they alter the way we think?'''\n",
    "\n",
    "article_content = re.sub(r'[[0-9]*]', ' ', article_content)\n",
    "article_content = re.sub(r's+', ' ', article_content)\n",
    "\n",
    "formatted_article_content = re.sub('[^a-zA-Z]', ' ', article_content )\n",
    "formatted_article_content = re.sub(r's+', ' ', formatted_article_content)\n",
    "\n",
    "tokens = word_tokenize(formatted_article_content)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punctuation = punctuation + '\\n'\n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in tokens:\n",
    "    if word.lower() not in stop_words:\n",
    "        if word.lower() not in punctuation:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "\n",
    "max_frequency = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word] / max_frequency\n",
    "\n",
    "sent_token = sent_tokenize(article_content)\n",
    "sentence_scores = {}\n",
    "\n",
    "for sent in sent_token:\n",
    "    sentence = sent.split()\n",
    "    for word in sentence:\n",
    "        if word.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.lower()]\n",
    "\n",
    "select_length = int(len(sent_token) * 0.2)\n",
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "final_summary = [word for word in summary]\n",
    "summary = ''.join(final_summary)\n",
    "summary = summary.replace('  ', ' ')\n",
    "\n",
    "print(len(article_content.split()), len(summary.split()), '\\n')\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}