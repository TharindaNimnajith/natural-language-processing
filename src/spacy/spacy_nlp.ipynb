{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Tokenization - Segmenting text into words, punctuations marks etc.\n",
    "\n",
    "# Part-of-speech (POS) Tagging - Assigning word types to tokens, like verb or noun.\n",
    "\n",
    "# Dependency Parsing - Assigning syntactic dependency labels, describing the relations\n",
    "# between individual tokens, like subject or object.\n",
    "\n",
    "# Lemmatization\t- Assigning the base forms of words. For example, the lemma of 'was'\n",
    "# is 'be', and the lemma of 'rats' is 'rat'.\n",
    "\n",
    "# Sentence Boundary Detection (SBD)\t- Finding and segmenting individual sentences.\n",
    "\n",
    "# Named Entity Recognition (NER) - Labelling named 'real-world' objects, like persons,\n",
    "# companies or locations.\n",
    "\n",
    "# Entity Linking (EL) - Disambiguating textual entities to unique identifiers in a\n",
    "# knowledge base.\n",
    "\n",
    "# Similarity - Comparing words, text spans and documents and how similar they are to each\n",
    "# other.\n",
    "\n",
    "# Text Classification - Assigning categories or labels to a whole document, or parts of a\n",
    "# document.\n",
    "\n",
    "# Rule-based Matching - Finding sequences of tokens based on their texts and linguistic\n",
    "# annotations, similar to regular expressions.\n",
    "\n",
    "# Training - Updating and improving a statistical model’s predictions.\n",
    "\n",
    "# Serialization\t- Saving objects to files or byte strings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP dobj X.X. False False\n",
      "startup startup NOUN NN advcl xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "# Text: The original word text.\n",
    "# Lemma: The base form of the word.\n",
    "# POS: The simple Universal POS part-of-speech tag.\n",
    "# Tag: The detailed part-of-speech tag.\n",
    "# Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "# Shape: The word shape – capitalization, punctuation, digits.\n",
    "# is alpha: Is the token an alpha character?\n",
    "# is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_,\n",
    "          token.is_alpha, token.is_stop)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "# ent: named entity\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "# Text: The original token text.\n",
    "# has vector: Does the token have a vector representation?\n",
    "# Vector norm: The L2 norm of the token’s vector (sqrt of the sum of the values squared)\n",
    "# OOV: Out-of-vocabulary\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "tokens = nlp('dog cat banana afskfsd')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.7799485853415737\n",
      "salty fries <-> hamburgers 0.7304624\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')  # make sure to use larger package!\n",
    "\n",
    "doc1 = nlp('I like salty fries and hamburgers.')\n",
    "doc2 = nlp('Fast food tastes very good.')\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, '<->', doc2, doc1.similarity(doc2))\n",
    "\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, '<->', burgers, french_fries.similarity(burgers))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197928453018144401\n",
      "coffee\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('I love coffee')\n",
    "\n",
    "print(doc.vocab.strings['coffee'])\n",
    "print(doc.vocab.strings[3197928453018144401])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4690420944186131903 X I I True False True en\n",
      "love 3702023516439754181 xxxx l ove True False False en\n",
      "coffee 3197928453018144401 xxxx c fee True False False en\n"
     ]
    }
   ],
   "source": [
    "# Text: The original text of the lexeme.\n",
    "# Orth: The hash value of the lexeme.\n",
    "# Shape: The abstract word shape of the lexeme.\n",
    "# Prefix: By default, the first letter of the word string.\n",
    "# Suffix: By default, the last three letters of the word string.\n",
    "# is alpha: Does the lexeme consist of alphabetic characters?\n",
    "# is digit: Does the lexeme consist of digits?\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('I love coffee')\n",
    "\n",
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
    "          lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}